2015-08-14 10:18:43 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 10:18:43 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 10:18:43 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 10:18:43 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 10:18:43 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 10:18:43 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 10:18:43 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 10:18:43 [scrapy] INFO: Spider opened
2015-08-14 10:18:43 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 10:18:43 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 10:18:43 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-14 10:18:44 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-14 10:18:44 [book_info] DEBUG: author: Noah Gift, Jeremy Jones
2015-08-14 10:18:44 [book_info] DEBUG: fields: [u"O'Reilly Media", u'2008-08-22', u'458', u'USD 49.99', u'Paperback', u'9780596515829']
2015-08-14 10:18:44 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-14 10:18:44 [scrapy] INFO: Closing spider (finished)
2015-08-14 10:18:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28980,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 2, 18, 44, 639305),
 'item_scraped_count': 1,
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 14, 2, 18, 43, 861510)}
2015-08-14 10:18:44 [scrapy] INFO: Spider closed (finished)
2015-08-14 10:30:05 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 10:30:05 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 10:30:05 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 10:30:05 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 10:30:05 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 10:30:05 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 10:30:05 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 10:30:05 [scrapy] INFO: Spider opened
2015-08-14 10:30:05 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 10:30:05 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 10:30:05 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-14 10:30:05 [book_info] DEBUG: detail_url: http://book.douban.com/subject/3033853/
2015-08-14 10:30:06 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-14 10:30:06 [book_info] DEBUG: author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-14 10:30:06 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-14 10:30:06 [scrapy] INFO: Closing spider (finished)
2015-08-14 10:30:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29005,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 2, 30, 6, 374991),
 'item_scraped_count': 1,
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 14, 2, 30, 5, 576756)}
2015-08-14 10:30:06 [scrapy] INFO: Spider closed (finished)
2015-08-14 10:32:43 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 10:32:43 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 10:32:43 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 10:32:44 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 10:32:44 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 10:32:44 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 10:32:44 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 10:32:44 [scrapy] INFO: Spider opened
2015-08-14 10:32:44 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 10:32:44 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 10:32:44 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-14 10:32:44 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-14 10:32:44 [book_info] DEBUG: author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-14 10:32:44 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-14 10:32:44 [scrapy] INFO: Closing spider (finished)
2015-08-14 10:32:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29187,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 2, 32, 44, 973317),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 14, 2, 32, 44, 179647)}
2015-08-14 10:32:44 [scrapy] INFO: Spider closed (finished)
2015-08-14 10:56:18 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 10:56:18 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 10:56:18 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 10:56:18 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 10:56:18 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 10:56:18 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 10:56:18 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 10:56:18 [scrapy] INFO: Spider opened
2015-08-14 10:56:18 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 10:56:18 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 10:56:19 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=None&cat=1001> (referer: None)
2015-08-14 10:56:19 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1880178/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:19 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/4234104/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:19 [scrapy] DEBUG: Crawled (200) <GET http://read.douban.com/ebook/2935218/?dcs=book-search> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:19 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3036620/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:19 [book_info] DEBUG: author: Sixpence None the Richer, publisher: Word Music, publish_year: 2003-05-01, page: 99, price: USD 14.95, binding: Paperback, isbn: 9780634065538
2015-08-14 10:56:19 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1880178/>
{'author': u'Sixpence None the Richer',
 'isbn': u'9780634065538',
 'page': u'99',
 'price': u'USD 14.95',
 'publish_year': u'2003-05-01',
 'publisher': u'Word Music'}
2015-08-14 10:56:20 [book_info] DEBUG: author: 崎谷はるひ, publisher: 角川書店 角川ルビー文庫, publish_year: 2006/12, page: 301ページ, price: 税込価格：¥600 （本体：¥571）, binding: 文庫, isbn: 9784044468170
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/4234104/>
{'author': u'\u5d0e\u8c37\u306f\u308b\u3072',
 'isbn': u'9784044468170',
 'page': u'301\u30da\u30fc\u30b8',
 'price': u'\u7a0e\u8fbc\u4fa1\u683c\uff1a\xa5600 \uff08\u672c\u4f53\uff1a\xa5571\uff09',
 'publish_year': u'2006/12',
 'publisher': u'\u89d2\u5ddd\u66f8\u5e97 \u89d2\u5ddd\u30eb\u30d3\u30fc\u6587\u5eab'}
2015-08-14 10:56:20 [scrapy] ERROR: Spider error processing <GET http://read.douban.com/ebook/2935218/?dcs=book-search> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:20 [book_info] DEBUG: author: Werner Holzwarth (Author),, Wolf Erlbruch (Illustrator), publisher: Chrysalis Children's Books, publish_year: 15 Sep 1994, page: 24, price: £4.49, binding: Hardcover, isbn: 9781856021012
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3036620/>
{'author': u'Werner Holzwarth (Author),, Wolf Erlbruch (Illustrator)',
 'isbn': u'9781856021012',
 'page': u'24',
 'price': u'\xa34.49',
 'publish_year': u'15 Sep 1994',
 'publisher': u"Chrysalis Children's Books"}
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1922050/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1381036/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1840972/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3006581/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1573689/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [book_info] DEBUG: author: Agatha Christie, publisher: Perfection Learning Prebound, publish_year: Ten Little Indians, page: 1977-07, price: USD 13.19, binding: Hardcover, isbn: 9780812415056
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1922050/>
{'author': u'Agatha Christie',
 'isbn': u'9780812415056',
 'page': u'1977-07',
 'price': u'USD 13.19',
 'publish_year': u'Ten Little Indians',
 'publisher': u'Perfection Learning Prebound'}
2015-08-14 10:56:20 [book_info] DEBUG: author: Agatha Christie, publisher: St. Martin's Press, publish_year: 2001-5-13, page: 288, price: 6.99美元, binding: 平装, isbn: 9780312979478
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1381036/>
{'author': u'Agatha Christie',
 'isbn': u'9780312979478',
 'page': u'288',
 'price': u'6.99\u7f8e\u5143',
 'publish_year': u'2001-5-13',
 'publisher': u"St. Martin's Press"}
2015-08-14 10:56:20 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/1840972/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/6131421/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [book_info] DEBUG: author: [英] 阿加莎・克里斯蒂, 祁阿红, 阿加莎·克里斯蒂侦探推理系列, publisher: 人民文学出版社, publish_year: And Then There Were None, page: 2008-3, price: 254, binding: 19.00, isbn: 平装
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3006581/>
{'author': u'[\u82f1] \u963f\u52a0\u838e\u30fb\u514b\u91cc\u65af\u8482, \u7941\u963f\u7ea2, \u963f\u52a0\u838e\xb7\u514b\u91cc\u65af\u8482\u4fa6\u63a2\u63a8\u7406\u7cfb\u5217',
 'isbn': u'\u5e73\u88c5',
 'page': u'2008-3',
 'price': u'254',
 'publish_year': u'And Then There Were None',
 'publisher': u'\u4eba\u6c11\u6587\u5b66\u51fa\u7248\u793e'}
2015-08-14 10:56:20 [book_info] DEBUG: author: Agatha Christie, Agatha Christie- HarperCollins 2003, publisher: Harper, publish_year: 2003-03-03, page: 224, price: GBP 6.99, binding: Paperback, isbn: 
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1573689/>
{'author': u'Agatha Christie, Agatha Christie- HarperCollins 2003',
 'isbn': u'',
 'page': u'224',
 'price': u'GBP 6.99',
 'publish_year': u'2003-03-03',
 'publisher': u'Harper'}
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/2719938/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/6131421/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:20 [book_info] DEBUG: author: Agatha Christie, publisher: St. Martin's Griffin, publish_year: 2004-05-03, page: 264, price: USD 13.95, binding: Paperback, isbn: 9780312330873
2015-08-14 10:56:20 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/2719938/>
{'author': u'Agatha Christie',
 'isbn': u'9780312330873',
 'page': u'264',
 'price': u'USD 13.95',
 'publish_year': u'2004-05-03',
 'publisher': u"St. Martin's Griffin"}
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/6131412/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1447021/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:20 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/6131412/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:20 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/1447021/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:21 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1827926/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:21 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/1827926/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:28 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/4515008/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:56:28 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/4515008/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:56:28 [scrapy] INFO: Closing spider (finished)
2015-08-14 10:56:28 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5217,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 281384,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 2, 56, 28, 316360),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/IndexError': 7,
 'start_time': datetime.datetime(2015, 8, 14, 2, 56, 18, 657705)}
2015-08-14 10:56:28 [scrapy] INFO: Spider closed (finished)
2015-08-14 10:57:16 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 10:57:16 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 10:57:16 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 10:57:17 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 10:57:17 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 10:57:17 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 10:57:17 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 10:57:17 [scrapy] INFO: Spider opened
2015-08-14 10:57:17 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 10:57:17 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=None&cat=1001> (referer: None)
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1880178/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://read.douban.com/ebook/2935218/?dcs=book-search> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1840972/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3036620/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/6131412/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [book_info] DEBUG: author: Sixpence None the Richer, publisher: Word Music, publish_year: 2003-05-01, page: 99, price: USD 14.95, binding: Paperback, isbn: 9780634065538
2015-08-14 10:57:17 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1880178/>
{'author': u'Sixpence None the Richer',
 'isbn': u'9780634065538',
 'page': u'99',
 'price': u'USD 14.95',
 'publish_year': u'2003-05-01',
 'publisher': u'Word Music'}
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/2719938/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [scrapy] ERROR: Spider error processing <GET http://read.douban.com/ebook/2935218/?dcs=book-search> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1447021/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/1840972/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:17 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/6131421/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:17 [book_info] DEBUG: author: Werner Holzwarth (Author),, Wolf Erlbruch (Illustrator), publisher: Chrysalis Children's Books, publish_year: 15 Sep 1994, page: 24, price: £4.49, binding: Hardcover, isbn: 9781856021012
2015-08-14 10:57:17 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3036620/>
{'author': u'Werner Holzwarth (Author),, Wolf Erlbruch (Illustrator)',
 'isbn': u'9781856021012',
 'page': u'24',
 'price': u'\xa34.49',
 'publish_year': u'15 Sep 1994',
 'publisher': u"Chrysalis Children's Books"}
2015-08-14 10:57:18 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/6131412/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:18 [book_info] DEBUG: author: Agatha Christie, publisher: St. Martin's Griffin, publish_year: 2004-05-03, page: 264, price: USD 13.95, binding: Paperback, isbn: 9780312330873
2015-08-14 10:57:18 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/2719938/>
{'author': u'Agatha Christie',
 'isbn': u'9780312330873',
 'page': u'264',
 'price': u'USD 13.95',
 'publish_year': u'2004-05-03',
 'publisher': u"St. Martin's Griffin"}
2015-08-14 10:57:18 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/1447021/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:18 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/6131421/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:18 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1827926/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:18 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/4234104/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:18 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1922050/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:18 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1381036/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:18 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/1827926/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:18 [book_info] DEBUG: author: 崎谷はるひ, publisher: 角川書店 角川ルビー文庫, publish_year: 2006/12, page: 301ページ, price: 税込価格：¥600 （本体：¥571）, binding: 文庫, isbn: 9784044468170
2015-08-14 10:57:18 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/4234104/>
{'author': u'\u5d0e\u8c37\u306f\u308b\u3072',
 'isbn': u'9784044468170',
 'page': u'301\u30da\u30fc\u30b8',
 'price': u'\u7a0e\u8fbc\u4fa1\u683c\uff1a\xa5600 \uff08\u672c\u4f53\uff1a\xa5571\uff09',
 'publish_year': u'2006/12',
 'publisher': u'\u89d2\u5ddd\u66f8\u5e97 \u89d2\u5ddd\u30eb\u30d3\u30fc\u6587\u5eab'}
2015-08-14 10:57:18 [book_info] DEBUG: author: Agatha Christie, publisher: Perfection Learning Prebound, publish_year: Ten Little Indians, page: 1977-07, price: USD 13.19, binding: Hardcover, isbn: 9780812415056
2015-08-14 10:57:18 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1922050/>
{'author': u'Agatha Christie',
 'isbn': u'9780812415056',
 'page': u'1977-07',
 'price': u'USD 13.19',
 'publish_year': u'Ten Little Indians',
 'publisher': u'Perfection Learning Prebound'}
2015-08-14 10:57:18 [book_info] DEBUG: author: Agatha Christie, publisher: St. Martin's Press, publish_year: 2001-5-13, page: 288, price: 6.99美元, binding: 平装, isbn: 9780312979478
2015-08-14 10:57:18 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1381036/>
{'author': u'Agatha Christie',
 'isbn': u'9780312979478',
 'page': u'288',
 'price': u'6.99\u7f8e\u5143',
 'publish_year': u'2001-5-13',
 'publisher': u"St. Martin's Press"}
2015-08-14 10:57:18 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/1573689/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:18 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3006581/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:18 [book_info] DEBUG: author: Agatha Christie, Agatha Christie- HarperCollins 2003, publisher: Harper, publish_year: 2003-03-03, page: 224, price: GBP 6.99, binding: Paperback, isbn: 
2015-08-14 10:57:18 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/1573689/>
{'author': u'Agatha Christie, Agatha Christie- HarperCollins 2003',
 'isbn': u'',
 'page': u'224',
 'price': u'GBP 6.99',
 'publish_year': u'2003-03-03',
 'publisher': u'Harper'}
2015-08-14 10:57:18 [book_info] DEBUG: author: [英] 阿加莎・克里斯蒂, 祁阿红, 阿加莎·克里斯蒂侦探推理系列, publisher: 人民文学出版社, publish_year: And Then There Were None, page: 2008-3, price: 254, binding: 19.00, isbn: 平装
2015-08-14 10:57:18 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3006581/>
{'author': u'[\u82f1] \u963f\u52a0\u838e\u30fb\u514b\u91cc\u65af\u8482, \u7941\u963f\u7ea2, \u963f\u52a0\u838e\xb7\u514b\u91cc\u65af\u8482\u4fa6\u63a2\u63a8\u7406\u7cfb\u5217',
 'isbn': u'\u5e73\u88c5',
 'page': u'2008-3',
 'price': u'254',
 'publish_year': u'And Then There Were None',
 'publisher': u'\u4eba\u6c11\u6587\u5b66\u51fa\u7248\u793e'}
2015-08-14 10:57:57 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/4515008/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
2015-08-14 10:57:57 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/4515008/> (referer: http://book.douban.com/subject_search?search_text=None&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 22, in parse_book_info
    author, fields[0], fields[1], fields[2], fields[3], fields[4], fields[5])
IndexError: list index out of range
2015-08-14 10:57:57 [scrapy] INFO: Closing spider (finished)
2015-08-14 10:57:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5217,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 281445,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 2, 57, 57, 860570),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/IndexError': 7,
 'start_time': datetime.datetime(2015, 8, 14, 2, 57, 17, 266930)}
2015-08-14 10:57:57 [scrapy] INFO: Spider closed (finished)
2015-08-14 11:06:26 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 11:06:26 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 11:06:26 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 11:06:26 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 11:06:26 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 11:06:26 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 11:06:26 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 11:06:26 [scrapy] INFO: Spider opened
2015-08-14 11:06:26 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 11:06:26 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 11:06:27 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-14 11:06:27 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-14 11:06:28 [book_info] DEBUG: author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-14 11:06:28 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-14 11:06:28 [scrapy] INFO: Closing spider (finished)
2015-08-14 11:06:28 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29124,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 3, 6, 28, 52729),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 14, 3, 6, 26, 866404)}
2015-08-14 11:06:28 [scrapy] INFO: Spider closed (finished)
2015-08-14 11:42:41 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 11:42:41 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 11:42:41 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'scrawler'}
2015-08-14 11:42:41 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-08-14 11:42:41 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 11:42:41 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 11:42:41 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 11:42:41 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 11:42:41 [root] DEBUG: Using default logger
2015-08-14 11:42:41 [root] DEBUG: Using default logger
2015-08-14 11:46:12 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 11:46:12 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 11:46:12 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'scrawler'}
2015-08-14 11:46:13 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-08-14 11:46:13 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 11:46:13 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 11:46:13 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 11:46:13 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-14 11:46:13 [scrapy] INFO: Spider opened
2015-08-14 11:46:13 [scrapy] DEBUG: Redirecting (301) to <GET http://book.douban.com/subject/3033853/> from <GET http://book.douban.com/subject/3033853>
2015-08-14 11:46:13 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: None)
2015-08-14 11:46:14 [root] DEBUG: Using default logger
2015-08-14 11:46:14 [root] DEBUG: Using default logger
2015-08-14 14:58:48 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-14 14:58:48 [scrapy] INFO: Optional features available: ssl, http11
2015-08-14 14:58:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-14 14:58:48 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-14 14:58:48 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-14 14:58:48 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-14 14:58:48 [scrapy] INFO: Enabled item pipelines: 
2015-08-14 14:58:48 [scrapy] INFO: Spider opened
2015-08-14 14:58:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-14 14:58:48 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-14 14:59:02 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-14 14:59:02 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-14 14:59:03 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-14 14:59:03 [book_info] DEBUG: content_desc: <div class ......
2015-08-14 14:59:03 [book_info] DEBUG: author_desc: <div class ......
2015-08-14 14:59:03 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u'<div class="intro">\n    <p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>    <p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>    <p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>    <p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>    <p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O\'Reilly, and MacTech. His consulting company\'s website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>    <p>He has a Master\'s degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>    <p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p></div>',
 'content_desc': u'<div class="intro">\n    <p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>    <p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you\'ll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>    <p>* Read text files and extract information</p>    <p>* Run tasks concurrently using the threading and forking options</p>    <p>* Get information from one process to another using network facilities</p>    <p>* Create clickable GUIs to handle large and complex utilities</p>    <p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>    <p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>    <p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>    <p>* Solve unique data backup challenges with customized scripts</p>    <p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>    <p>With this book, you\'ll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You\'ll also learn about several Python-related technologies that will make your life much easier.</p></div>',
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-14 14:59:03 [scrapy] INFO: Closing spider (finished)
2015-08-14 14:59:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29161,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 14, 6, 59, 3, 38405),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 14, 6, 58, 48, 756019)}
2015-08-14 14:59:03 [scrapy] INFO: Spider closed (finished)
2015-08-15 10:59:34 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 10:59:34 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 10:59:34 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-15 10:59:34 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-15 10:59:34 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 10:59:34 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 10:59:34 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 10:59:34 [scrapy] INFO: Spider opened
2015-08-15 10:59:34 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-15 10:59:34 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 10:59:34 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-15 10:59:34 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-15 10:59:34 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 25, in parse_book_info
    evaluate = response.css('#interest_sectl .ll.rating_num::text').extract()[0].strip(' \r\n\t')
IndexError: list index out of range
2015-08-15 10:59:34 [scrapy] INFO: Closing spider (finished)
2015-08-15 10:59:34 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 16459,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 15, 2, 59, 34, 958744),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2015, 8, 15, 2, 59, 34, 567591)}
2015-08-15 10:59:34 [scrapy] INFO: Spider closed (finished)
2015-08-15 11:00:02 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 11:00:02 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 11:00:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-15 11:00:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-15 11:00:02 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 11:00:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 11:00:02 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 11:00:02 [scrapy] INFO: Spider opened
2015-08-15 11:00:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-15 11:00:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 11:00:02 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-15 11:00:03 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-15 11:00:03 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-15 11:00:03 [book_info] DEBUG: content_desc: <div class ......
2015-08-15 11:00:03 [book_info] DEBUG: author_desc: <div class ......
2015-08-15 11:00:03 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u'<div class="intro">\n    <p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>    <p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>    <p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>    <p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>    <p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O\'Reilly, and MacTech. His consulting company\'s website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>    <p>He has a Master\'s degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>    <p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p></div>',
 'content_desc': u'<div class="intro">\n    <p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>    <p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you\'ll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>    <p>* Read text files and extract information</p>    <p>* Run tasks concurrently using the threading and forking options</p>    <p>* Get information from one process to another using network facilities</p>    <p>* Create clickable GUIs to handle large and complex utilities</p>    <p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>    <p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>    <p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>    <p>* Solve unique data backup challenges with customized scripts</p>    <p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>    <p>With this book, you\'ll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You\'ll also learn about several Python-related technologies that will make your life much easier.</p></div>',
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-15 11:00:03 [scrapy] INFO: Closing spider (finished)
2015-08-15 11:00:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28913,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 15, 3, 0, 3, 538459),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 15, 3, 0, 2, 498775)}
2015-08-15 11:00:03 [scrapy] INFO: Spider closed (finished)
2015-08-15 17:09:17 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 17:09:17 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 17:09:17 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'scrawler'}
2015-08-15 17:09:17 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-08-15 17:09:17 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 17:09:17 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 17:09:17 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 17:09:17 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 17:09:17 [root] DEBUG: Using default logger
2015-08-15 17:09:17 [root] DEBUG: Using default logger
2015-08-15 17:09:52 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 17:09:52 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 17:09:52 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'scrawler'}
2015-08-15 17:09:52 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-08-15 17:09:52 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 17:09:52 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 17:09:52 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 17:09:52 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 17:09:52 [scrapy] INFO: Spider opened
2015-08-15 17:09:53 [scrapy] DEBUG: Crawled (200) <GET http://doc.scrapy.org/en/latest/_static/selectors-sample1.html> (referer: None)
2015-08-15 17:09:54 [root] DEBUG: Using default logger
2015-08-15 17:09:54 [root] DEBUG: Using default logger
2015-08-15 17:27:15 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 17:27:15 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 17:27:15 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'scrawler'}
2015-08-15 17:27:15 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-08-15 17:27:15 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 17:27:15 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 17:27:15 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 17:27:15 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-15 17:27:15 [scrapy] INFO: Spider opened
2015-08-15 17:27:15 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853> (referer: None)
2015-08-15 17:27:16 [root] DEBUG: Using default logger
2015-08-15 17:27:16 [root] DEBUG: Using default logger
2015-08-15 17:28:11 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 17:28:11 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 17:28:11 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'scrawler'}
2015-08-15 17:28:11 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-08-15 17:28:11 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 17:28:11 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 17:28:11 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 17:28:11 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-15 17:28:11 [scrapy] INFO: Spider opened
2015-08-15 17:28:11 [scrapy] DEBUG: Redirecting (301) to <GET http://book.douban.com/subject/3033853/> from <GET http://book.douban.com/subject/3033853>
2015-08-15 17:28:12 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: None)
2015-08-15 17:28:13 [root] DEBUG: Using default logger
2015-08-15 17:28:13 [root] DEBUG: Using default logger
2015-08-15 17:53:02 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 17:53:02 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 17:53:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-15 17:53:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-15 17:53:03 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 17:53:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 17:53:03 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 17:53:03 [scrapy] INFO: Spider opened
2015-08-15 17:53:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-15 17:53:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 17:53:03 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-15 17:53:03 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-15 17:53:04 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 25, in parse_book_info
    fields = [item for item in strip(response.css('#info::text').extract()) if '\n' not in item]
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/util/text.py", line 7, in strip
    yield text.strip(' \r\n\t')
AttributeError: 'list' object has no attribute 'strip'
2015-08-15 17:53:04 [scrapy] INFO: Closing spider (finished)
2015-08-15 17:53:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28922,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 15, 9, 53, 4, 33367),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2015, 8, 15, 9, 53, 3, 113393)}
2015-08-15 17:53:04 [scrapy] INFO: Spider closed (finished)
2015-08-15 17:54:38 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 17:54:38 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 17:54:38 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-15 17:54:39 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-15 17:54:39 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 17:54:39 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 17:54:39 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 17:54:39 [scrapy] INFO: Spider opened
2015-08-15 17:54:39 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-15 17:54:39 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 17:54:39 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-15 17:54:40 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-15 17:54:40 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 29, in parse_book_info
    content_desc = '\n'.join(strip(intro[0].css('p').extract()))
TypeError: sequence item 0: expected string, list found
2015-08-15 17:54:40 [scrapy] INFO: Closing spider (finished)
2015-08-15 17:54:40 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28902,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 15, 9, 54, 40, 229066),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 8, 15, 9, 54, 39, 217929)}
2015-08-15 17:54:40 [scrapy] INFO: Spider closed (finished)
2015-08-15 18:26:53 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-15 18:26:53 [scrapy] INFO: Optional features available: ssl, http11
2015-08-15 18:26:53 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-15 18:26:53 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-15 18:26:53 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-15 18:26:54 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-15 18:26:54 [scrapy] INFO: Enabled item pipelines: 
2015-08-15 18:26:54 [scrapy] INFO: Spider opened
2015-08-15 18:26:54 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-15 18:26:54 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-15 18:26:54 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-15 18:26:54 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-15 18:26:54 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: , publish_year: , page: O'Reilly Media, price: , binding: 2008-08-22, isbn: 
2015-08-15 18:26:54 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-15 18:26:54 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-15 18:26:54 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'',
 'page': u"O'Reilly Media",
 'price': u'',
 'publish_year': u'',
 'publisher': u''}
2015-08-15 18:26:54 [scrapy] INFO: Closing spider (finished)
2015-08-15 18:26:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28892,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 15, 10, 26, 54, 956836),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 15, 10, 26, 54, 3772)}
2015-08-15 18:26:54 [scrapy] INFO: Spider closed (finished)
2015-08-16 22:50:42 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 22:50:42 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 22:50:42 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 22:50:43 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 22:50:43 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 22:50:43 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 22:50:43 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 22:50:43 [scrapy] INFO: Spider opened
2015-08-16 22:50:43 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 22:50:43 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-16 22:50:43 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 22:50:43 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 22:50:43 [scrapy] ERROR: Spider error processing <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/spiders/book_info.py", line 26, in parse_book_info
    evaluate = strip(response.css('#interest_sectl .ll.rating_num::text').extract()[0])
IndexError: list index out of range
2015-08-16 22:50:43 [scrapy] INFO: Closing spider (finished)
2015-08-16 22:50:43 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 16478,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 14, 50, 43, 790548),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2015, 8, 16, 14, 50, 43, 353973)}
2015-08-16 22:50:43 [scrapy] INFO: Spider closed (finished)
2015-08-16 22:52:23 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 22:52:23 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 22:52:23 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 22:52:24 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 22:52:24 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 22:52:24 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 22:52:24 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 22:52:24 [scrapy] INFO: Spider opened
2015-08-16 22:52:24 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 22:52:24 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2015-08-16 22:52:24 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 22:52:24 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 22:52:25 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: , publish_year: , page: O'Reilly Media, price: , binding: 2008-08-22, isbn: 
2015-08-16 22:52:25 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 22:52:25 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 22:52:25 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'',
 'page': u"O'Reilly Media",
 'price': u'',
 'publish_year': u'',
 'publisher': u''}
2015-08-16 22:52:25 [scrapy] INFO: Closing spider (finished)
2015-08-16 22:52:25 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29111,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 14, 52, 25, 114701),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 14, 52, 24, 281011)}
2015-08-16 22:52:25 [scrapy] INFO: Spider closed (finished)
2015-08-16 23:01:42 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 23:01:42 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 23:01:42 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 23:01:43 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 23:01:43 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 23:01:43 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 23:01:43 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 23:01:43 [scrapy] INFO: Spider opened
2015-08-16 23:01:43 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 23:01:43 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-16 23:01:43 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 23:01:44 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 23:01:44 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-16 23:01:44 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 23:01:44 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 23:01:44 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-16 23:01:44 [scrapy] INFO: Closing spider (finished)
2015-08-16 23:01:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29011,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 15, 1, 44, 182419),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 15, 1, 43, 239036)}
2015-08-16 23:01:44 [scrapy] INFO: Spider closed (finished)
2015-08-16 23:08:33 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 23:08:33 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 23:08:33 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 23:08:33 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 23:08:33 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 23:08:33 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 23:08:33 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 23:08:33 [scrapy] INFO: Spider opened
2015-08-16 23:08:33 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 23:08:33 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-16 23:08:33 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 23:08:34 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 23:08:34 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-16 23:08:34 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 23:08:34 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 23:08:34 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-16 23:08:34 [scrapy] INFO: Closing spider (finished)
2015-08-16 23:08:34 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28958,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 15, 8, 34, 643656),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 15, 8, 33, 509039)}
2015-08-16 23:08:34 [scrapy] INFO: Spider closed (finished)
2015-08-16 23:15:44 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 23:15:44 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 23:15:44 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 23:15:44 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 23:15:44 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 23:15:44 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 23:15:44 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 23:15:44 [scrapy] INFO: Spider opened
2015-08-16 23:15:44 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 23:15:44 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-16 23:15:44 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 23:15:45 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 23:15:45 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-16 23:15:45 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 23:15:45 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 23:15:45 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-16 23:15:45 [scrapy] INFO: Closing spider (finished)
2015-08-16 23:15:45 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28954,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 15, 15, 45, 342256),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 15, 15, 44, 447091)}
2015-08-16 23:15:45 [scrapy] INFO: Spider closed (finished)
2015-08-16 23:15:59 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 23:15:59 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 23:15:59 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 23:15:59 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 23:16:00 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 23:16:00 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 23:16:00 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 23:16:00 [scrapy] INFO: Spider opened
2015-08-16 23:16:00 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 23:16:00 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-16 23:16:00 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 23:16:01 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 23:16:01 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-16 23:16:01 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 23:16:01 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 23:16:01 [scrapy] ERROR: Error processing {'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/pipelines/mongodb.py", line 34, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/usr/local/lib/python2.7/site-packages/pymongo/collection.py", line 1926, in insert
    check_keys, manipulate, write_concern)
  File "/usr/local/lib/python2.7/site-packages/pymongo/collection.py", line 431, in _insert
    _check_write_command_response(results)
  File "/usr/local/lib/python2.7/site-packages/pymongo/helpers.py", line 260, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error index: douban.book_info.$isbn dup key: { : "9780596515829" }
2015-08-16 23:16:01 [scrapy] INFO: Closing spider (finished)
2015-08-16 23:16:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 28844,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 15, 16, 1, 342634),
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 15, 16, 0, 80202)}
2015-08-16 23:16:01 [scrapy] INFO: Spider closed (finished)
2015-08-16 23:21:04 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 23:21:04 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 23:21:04 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 23:21:04 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 23:21:04 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 23:21:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 23:21:04 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 23:21:04 [scrapy] INFO: Spider opened
2015-08-16 23:21:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 23:21:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-16 23:21:05 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 23:21:05 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 23:21:06 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-16 23:21:06 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 23:21:06 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 23:21:06 [scrapy] ERROR: Error processing {'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/michael/Documents/workspace/myopensource/scrawler/scrawler/pipelines/mongodb.py", line 35, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/usr/local/lib/python2.7/site-packages/pymongo/collection.py", line 1926, in insert
    check_keys, manipulate, write_concern)
  File "/usr/local/lib/python2.7/site-packages/pymongo/collection.py", line 431, in _insert
    _check_write_command_response(results)
  File "/usr/local/lib/python2.7/site-packages/pymongo/helpers.py", line 260, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error index: douban.book_info.$isbn dup key: { : "9780596515829" }
2015-08-16 23:21:06 [scrapy] INFO: Closing spider (finished)
2015-08-16 23:21:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29135,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 15, 21, 6, 27301),
 'log_count/DEBUG': 6,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 15, 21, 4, 906263)}
2015-08-16 23:21:06 [scrapy] INFO: Spider closed (finished)
2015-08-16 23:22:44 [scrapy] INFO: Scrapy 1.0.2 started (bot: scrawler)
2015-08-16 23:22:44 [scrapy] INFO: Optional features available: ssl, http11
2015-08-16 23:22:44 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrawler.spiders', 'SPIDER_MODULES': ['scrawler.spiders'], 'LOG_FILE': 'logs/scrapy.log', 'BOT_NAME': 'scrawler'}
2015-08-16 23:22:45 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-08-16 23:22:45 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-08-16 23:22:45 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-08-16 23:22:45 [scrapy] INFO: Enabled item pipelines: MongoPipeLine
2015-08-16 23:22:45 [scrapy] INFO: Spider opened
2015-08-16 23:22:45 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-08-16 23:22:45 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-08-16 23:22:45 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject_search?search_text=9780596515829&cat=1001> (referer: None)
2015-08-16 23:22:46 [scrapy] DEBUG: Crawled (200) <GET http://book.douban.com/subject/3033853/> (referer: http://book.douban.com/subject_search?search_text=9780596515829&cat=1001)
2015-08-16 23:22:46 [book_info] DEBUG: evaluate: 7.6, author: Noah Gift, Jeremy Jones, publisher: O'Reilly Media, publish_year: 2008-08-22, page: 458, price: USD 49.99, binding: Paperback, isbn: 9780596515829
2015-08-16 23:22:46 [book_info] DEBUG: content_desc: <p>Python  ......
2015-08-16 23:22:46 [book_info] DEBUG: author_desc: <p>Jeremy  ......
2015-08-16 23:22:46 [scrapy] DEBUG: Scraped from <200 http://book.douban.com/subject/3033853/>
{'author': u'Noah Gift, Jeremy Jones',
 'author_desc': u"<p>Jeremy Jones Jeremy Jones is a software engineer who works for Predictix. His weapon of choice is Python, but he has done some shell, plenty of Perl, a touch of Java, is currently learning C#, and finds functional programming languages (especially OCaml) fascinating.</p>\n<p>He is the author of the open source projects Munkware, a multiproducer/multiconsumer, transactional, and persistent queuing mechanism, ediplex, an EDI (Electronic Data Interchange) parsing engine, and podgrabber a podcast downloader. All three projects were written in the Python language.</p>\n<p>Jeremy spends his spare time enjoying his family and doing a little writing. He lives in Conyers, Georgia, just east of Atlanta, with his wife, Debra; two children, Zane and Justus; a Lab named Genevieve (how Madelinesque).</p>\n<p>Opinions and views expressed by Jeremy are his own and not those of Predictix.</p>\n<p>Noah Gift Noah Gift is an author, speaker, consultant, and community leader, writing for publications such as IBM Developerworks, Red Hat Magazine, O'Reilly, and MacTech. His consulting company's website is www.giftcs.com , and his personal website is www.noahgift.com . Noah is also the current organizer for www.pyatl.org , which is the Python User Group for Atlanta, GA. He has given presentations at PyCon and PyAtl.</p>\n<p>He has a Master's degree in CIS from Cal State Los Angeles, B.S. in Nutritional Science from Cal Poly San Luis Obispo, is an Apple and LPI certified SysAdmin, and has worked at companies such as, Caltech, Disney Feature Animation, Sony Imageworks, and Turner Studios.</p>\n<p>In his free time he enjoys spending time with his wife Leah, and their son Liam, playing the piano, and exercising religiously.</p>",
 'content_desc': u"<p>Python is an ideal language for solving problems, especially in Linux and Unix networks. With this pragmatic book, administrators can review various tasks that often occur in the management of these systems, and learn how Python can provide a more efficient and less painful way to handle them.</p>\n<p>Each chapter in Python for Unix and Linux System Administration presents a particular administrative issue, such as concurrency or data backup, and presents Python solutions through hands-on examples. Once you finish this book, you'll be able to develop your own set of command-line utilities with Python to tackle a wide range of problems. Discover how this language can help you:</p>\n<p>* Read text files and extract information</p>\n<p>* Run tasks concurrently using the threading and forking options</p>\n<p>* Get information from one process to another using network facilities</p>\n<p>* Create clickable GUIs to handle large and complex utilities</p>\n<p>* Monitor large clusters of machines by interacting with SNMP programmatically</p>\n<p>* Master the IPython Interactive Python shell to replace or augment Bash, Korn, or Z-Shell</p>\n<p>* Integrate Cloud Computing into your infrastructure, and learn to write a Google App Engine Application</p>\n<p>* Solve unique data backup challenges with customized scripts</p>\n<p>* Interact with MySQL, SQLite, Oracle, Postgres, Django ORM, and SQLAlchemy</p>\n<p>With this book, you'll learn how to package and deploy your Python applications and libraries, and write code that runs equally well on multiple Unix platforms. You'll also learn about several Python-related technologies that will make your life much easier.</p>",
 'douban_url': 'http://book.douban.com/subject/3033853/',
 'evaluate': u'7.6',
 'isbn': u'9780596515829',
 'page': u'458',
 'price': u'USD 49.99',
 'publish_year': u'2008-08-22',
 'publisher': u"O'Reilly Media"}
2015-08-16 23:22:46 [scrapy] INFO: Closing spider (finished)
2015-08-16 23:22:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 601,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29180,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 8, 16, 15, 22, 46, 588939),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2015, 8, 16, 15, 22, 45, 292414)}
2015-08-16 23:22:46 [scrapy] INFO: Spider closed (finished)
